{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KORA_S3S4 Data Analysis - Minimum Model\n",
    "\n",
    "import math \n",
    "import numpy as np\n",
    "import statistics\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pandas_profiling as pp\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import impute\n",
    "import pandas_profiling as pp\n",
    "import nbimporter\n",
    "import Modeling\n",
    "from IPython.core.debugger import set_trace\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor, VotingRegressor\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "import statsmodels.api as sts\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data and data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "KORA_Noise_noMissing = pd.read_csv('C:\\\\Users\\\\sahar.behzadi\\\\Desktop\\\\Noise2Nako\\\\Data\\\\KORA_S3_S4\\\\KORA_Noise_noMissing_median.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Inputs\n",
    "\n",
    "X = KORA_Noise_noMissing.drop(['hyper_p', 'bp_diast', 'bp_syst'], axis = 1)\n",
    "X_mini = KORA_Noise_noMissing[['sex', 'age', 'bmi', 'smoking', 'lden_org']]\n",
    "X_mini.head()\n",
    "\n",
    "# Output\n",
    "\n",
    "Y_hyper = KORA_Noise_noMissing['hyper_p'].astype(int)\n",
    "Y_SBP = KORA_Noise_noMissing['bp_syst']\n",
    "Y_DBP = KORA_Noise_noMissing['bp_diast']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explainable AI - Categories\n",
    "#### \n",
    "<img src='img/XAI_categories.png' style='width:15cm;height:8cm'>  \n",
    "\n",
    "1. <b> Perturbation-based : </b>\n",
    "Check what happens to the classifier or the regressor when some chnages happen to the input, e.g. masking the input image and see which features are more important.\n",
    "\n",
    "- <b> Dis: </b>\n",
    "slow\n",
    "assumes locality (may different features are important to the task!)\n",
    "perturbation may introduce artefacts (the way we manipulate the input could have some impacts on the results)\n",
    "\n",
    "\n",
    "2. <b> Function-based: </b>\n",
    "Find the functional perspective of the model and try to intrepret the resuts by the function. Approximate the function by e.g. Taylor decomposition (expansion)\n",
    "\n",
    "- <b> Dis:</b>\n",
    "Need to find a good root point where to perform the expansion\n",
    "\n",
    "- <b> Adv:</b>\n",
    "Can be applied to any model!\n",
    "\n",
    "3. <b> Sampling-based:</b>\n",
    "We approximate the prediction locally. (Gradient * Input)\n",
    "\n",
    "- <b> Dis:</b>\n",
    "They are very local! Do not measure global impacts.\n",
    "\n",
    "- <b> Adv:</b>\n",
    "Fast, no optimization is required\n",
    "\n",
    "4. <b> Stuctured-based:</b>\n",
    "They use the structure of the model to explain the prediction. (Layer-wise Relevance Propagation - LRP). Decompose the function by using the structure and explain the easier function and aggregate them later. \n",
    "\n",
    "<b>Intuition :</b> Every layer in a NN, for instance, is a composition of simpler functions (e.g., Relu) \n",
    "\n",
    "<img src='img/LRP.png' style='width:15cm;height:8cm'>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import xgboost\n",
    "shap.initjs()\n",
    "model = xgboost.XGBRegressor().fit(X_mini, Y_SBP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import shap\n",
    "import xgboost\n",
    "shap.initjs()\n",
    "model = xgboost.XGBRegressor().fit(X_mini, Y_SBP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP Algorithm\n",
    "\n",
    "SHAP assigns each feature an importance value for a particular prediction. \n",
    "\n",
    "#### 1. They introduce the perspective of viewing any explanation of a modelâ€™s prediction as a model itself, which they term the explanation model, by defining the class of additive feature attribution methods. \n",
    "For complex models, such as ensemble methods or deep networks, we cannot use the original model as its own best explanation because it is not easy to understand. Instead, we must use a simpler explanation model, which we define as any <b> interpretable approximation of the original model </b>. \n",
    "A surprising attribute of the class of additive feature attribution methods is the presence of a single unique solution in this class with three desirable properties (described below).\n",
    "\n",
    "#### 2. Thy then show that game theory results guaranteeing a unique solution apply to the entire class of additive feature attribution methods and propose SHAP values as a unified measure of feature importance that various methods approximate.\n",
    "\n",
    "#### 3. They propose new SHAP value estimation methods and demonstrate that they are better aligned with human intuition as measured by user studies and more effectually discriminate among model output classes than several existing methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explain the model's predictions using SHAP\n",
    "# (same syntax works for LightGBM, CatBoost, scikit-learn, transformers, Spark, etc.)\n",
    "explainer = shap.Explainer(model)\n",
    "shap_values = explainer(X_mini)\n",
    "\n",
    "# visualize the first prediction's explanation\n",
    "shap.plots.waterfall(shap_values[0])\n",
    "shap.plots.force(shap_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values[1])\n",
    "shap.plots.force(shap_values[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_mini.head(5))\n",
    "print(shap_values[1])\n",
    "shap_values[1].values / shap_values[1].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values[2])\n",
    "shap.plots.force(shap_values[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = X_mini.to_numpy()\n",
    "shap.initjs() \n",
    "shap.force_plot(explainer.expected_value, explainer.shap_values(X_mini), features=observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = X_mini.sample(100, random_state=42).to_numpy()\n",
    "shap.initjs() \n",
    "shap.force_plot(explainer.expected_value, explainer.shap_values(observations), features=observations,\n",
    "                feature_names=X_mini.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mini.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs() \n",
    "shap.summary_plot(explainer.shap_values(observations), features=observations, feature_names=X_mini.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dependence scatter plot to show the effect of a single feature across the whole dataset\n",
    "shap.plots.scatter(shap_values[:,\"lden_org\"], dot_size=2, x_jitter=0.5, color=shap_values[:,\"age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dependence scatter plot to show the effect of a single feature across the whole dataset\n",
    "shap.plots.scatter(shap_values[:,\"age\"], color=shap_values[:,\"lden_org\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dependence scatter plot to show the effect of a single feature across the whole dataset\n",
    "shap.plots.scatter(shap_values[:,\"bmi\"], color=shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create a dependence scatter plot to show the effect of a single feature across the whole dataset\n",
    "shap.plots.scatter(shap_values[:,\"age\"], color=shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a dependence scatter plot to show the effect of a single feature across the whole dataset\n",
    "shap.plots.scatter(shap_values[:,\"sex\"], dot_size=2, x_jitter=0.5, color=shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dependence scatter plot to show the effect of a single feature across the whole dataset\n",
    "shap.plots.scatter(shap_values[:,\"smoking\"], dot_size=2, x_jitter=0.5, color=shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mini.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
