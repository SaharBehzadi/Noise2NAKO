{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Predicting Mortality across Germany wih different AI Methods\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import impute\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor, VotingRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.svm import SVR, NuSVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import dbf\n",
    "from pygam import GAM, s, f, LinearGAM\n",
    "import xgboost\n",
    "import joblib\n",
    "import geopandas as gpd\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib as mpl\n",
    "from pprint import pprint\n",
    "from stabilityselection import Colinearity_Remover\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_grid_serach(method):\n",
    "    \n",
    "    ''' This function makes a grid for hyper-parameter tuning based on parameters of each method.\n",
    "        \n",
    "        Input:\n",
    "        --------------------------\n",
    "        method (str): name of the method\n",
    "        \n",
    "        Output:\n",
    "        ---------------------------\n",
    "        grid (dictionary): a grid containing ranges for hyper-parameters w.r.t. the specified method\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    # Create a parameter grid\n",
    "       \n",
    "    if (method == 'LR_Lasso'):\n",
    "        # n_alpha: Number of alphas along the regularization path\n",
    "        # eps: Length of the path\n",
    "        # cv: number of folds in built-in cross-validation\n",
    "        grid = {'n_alphas': [100, 200, 300],\n",
    "               'eps': [0.01, 0.001],\n",
    "               'cv': [5, 10]}\n",
    "        \n",
    "    if (method == 'LR_Ridge'):\n",
    "        # alpha: regularization strength\n",
    "        grid = {'cv': [5, 10]}\n",
    "        \n",
    "    if (method == 'LR_Elastic'):\n",
    "        # l1_ratio: scaling between Ridge and Lasso\n",
    "        # n_alpha: Number of alphas along the regularization path\n",
    "        # eps: Length of the path\n",
    "        grid = {'l1_ratio': [0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1],\n",
    "        'n_alphas': [100, 200, 300],\n",
    "        'eps': [0.01, 0.001],\n",
    "        'cv': [5, 10]\n",
    "        }\n",
    "        \n",
    "    if (method == 'RF'):\n",
    "        # Number of trees in random forest\n",
    "        n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 10)]\n",
    "        # Number of features to consider at every split\n",
    "        max_features = ['auto', 'sqrt']\n",
    "        # Maximum number of levels in tree\n",
    "        max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "        max_depth.append(None)\n",
    "        # Minimum number of samples required to split a node\n",
    "        min_samples_split = [2, 5, 10]\n",
    "        # Minimum number of samples required at each leaf node\n",
    "        min_samples_leaf = [1, 2, 4]\n",
    "        # Method of selecting samples for training each tree\n",
    "        bootstrap = [True, False]\n",
    "        # Create the random grid\n",
    "        grid = {'n_estimators': n_estimators,\n",
    "                       'max_features': max_features,\n",
    "                       'max_depth': max_depth,\n",
    "                       'min_samples_split': min_samples_split,\n",
    "                       'min_samples_leaf': min_samples_leaf,\n",
    "                       'bootstrap': bootstrap}\n",
    "        \n",
    "    elif (method == 'AdaB'):\n",
    "        # Number of trees in AdaBoost\n",
    "        n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 10)]\n",
    "        # The loss function to use when updating the weights after each boosting iteration\n",
    "        loss = ['linear', 'square', 'exponential']\n",
    "        # Weight applied to each regressor at each boosting iteration\n",
    "        learning_rate = [float(x) for x in np.linspace(0.1, 2, num = 20)]\n",
    "        # Create the random grid\n",
    "        grid = {'learning_rate': learning_rate,\n",
    "                       'loss': loss,\n",
    "                       'n_estimators': n_estimators}\n",
    "        \n",
    "    elif (method == 'XGBoost'):\n",
    "        # Number of gradient boosted trees\n",
    "        n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 10)]\n",
    "        # Boosting learning rate\n",
    "        learning_rate = [float(x) for x in np.linspace(0.01, 0.2, num = 20)]\n",
    "        # Create the random grid\n",
    "        grid = { 'max_depth': [3, 5, 6, 10, 15, 20],\n",
    "           'learning_rate': learning_rate,\n",
    "           'subsample': np.arange(0.5, 1.0, 0.1),\n",
    "           'colsample_bytree': np.arange(0.4, 1.0, 0.1),\n",
    "           'colsample_bylevel': np.arange(0.4, 1.0, 0.1),\n",
    "           'n_estimators': n_estimators}\n",
    "        \n",
    "    elif (method == 'SVR'):\n",
    "        # C parameter\n",
    "        C = [0.1, 1, 10, 100]\n",
    "        # kernel\n",
    "        kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "        # Create the random grid\n",
    "        grid = { \n",
    "            'C': C,\n",
    "           'kernel': kernel\n",
    "                      }\n",
    "        \n",
    "    elif (method == 'KNN'):\n",
    "        # Algorithm used to compute the nearest neighbors\n",
    "        algorithm = ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "        n_beighbors = list(range(1,30))\n",
    "#         Power parameter for the Minkowski metric. When p = 1, this is equivalent to using manhattan_distance (l1),\n",
    "#         and euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.\n",
    "        p = [1, 2]\n",
    "#         Weight function used in prediction\n",
    "        weight = ['uniform', 'distance']\n",
    "#         Leaf size passed to BallTree or KDTree. \n",
    "        leaf_size = list(range(1,50))\n",
    "        grid = {\n",
    "            'algorithm': algorithm,\n",
    "            'leaf_size': leaf_size,\n",
    "                       'n_neighbors': n_beighbors,\n",
    "                       'p': p,\n",
    "                       'weights': weight\n",
    "                      }\n",
    "    elif (method == 'MLP'):\n",
    "        \n",
    "        grid = {\n",
    "            'hidden_layer_sizes': [(150,100,50), (120,80,40), (100,50,30), (100,)],\n",
    "            'max_iter': [50, 100],\n",
    "            'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "            'solver': ['sgd', 'adam', 'invscaling'],\n",
    "            'alpha': [0.0001, 0.05],\n",
    "            'learning_rate': ['constant','adaptive'],\n",
    "            }\n",
    "    \n",
    "    pprint(grid)\n",
    "    \n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomSearch_Param_Tuning(model, method, itr, X, y, grid = None, n_cv = 5, verbose = 2, rand_state = 42, jobs = -1):\n",
    "    \n",
    "    ''' This function performs a random search for hyper-parameter tuning for the specified method.\n",
    "        \n",
    "        Input:\n",
    "        --------------------------\n",
    "        model (e.g. SKlearn models): it is a trained model\n",
    "        \n",
    "        method (str): name of the method\n",
    "        \n",
    "        itr (int): number of iterations\n",
    "        \n",
    "        X (pandas dataframe): data for the predictors\n",
    "        \n",
    "        y (pandas dataframe, pandas serie): output\n",
    "        \n",
    "        grid (dictionary): a grid containing ranges for hyper-parameters w.r.t. the specified method (optional)\n",
    "        \n",
    "        n_cv (int): number of folds in cross-validation\n",
    "        \n",
    "        verbose (int): Controls the verbosity, the higher, the more messages.\n",
    "        \n",
    "        rand_state (int): an integer to set and make the result reproducable\n",
    "                \n",
    "        jobs (int): number of cpus to specify for the parallelization \n",
    "        \n",
    "        Output:\n",
    "        ---------------------------\n",
    "        random_model.best_estimator_ (sklearn model): the best fitted model employing random search\n",
    "        \n",
    "        random_model.best_params_ (dictionary): list of the parameters for the best fitted model employing random search\n",
    "        \n",
    "        random_model (list of sklearn models): list of all tried methods employing random search\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    print('Runnig Random Search for hyper-parameter Tuning when Scoring is R-squared for ' + method + ' ..... ')\n",
    "    \n",
    "    if not grid:\n",
    "        grid = Create_grid_serach(method)\n",
    "\n",
    "    random_model = RandomizedSearchCV(estimator = model, param_distributions = grid, n_iter = itr, cv = n_cv,\n",
    "                                      scoring= 'r2', verbose=2, random_state=42, n_jobs = -1)\n",
    "    # Fit the random search model\n",
    "    random_model.fit(X, y)\n",
    "    \n",
    "    return random_model.best_estimator_, random_model.best_params_, random_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GridSearch_Param_Tuning(model, method, X, y, grid = None, n_cv = 5, verbose = 2, jobs = -1):\n",
    "\n",
    "    ''' This function performs a grid search for hyper-parameter tuning for the specified method.\n",
    "        \n",
    "        Input:\n",
    "        --------------------------\n",
    "        model (e.g. SKlearn models): it is a trained model\n",
    "        \n",
    "        method (str): name of the method\n",
    "        \n",
    "        X (pandas dataframe): data for the predictors\n",
    "        \n",
    "        y (pandas dataframe, pandas serie): output\n",
    "        \n",
    "        grid (dictionary): a grid containing ranges for hyper-parameters w.r.t. the specified method (optional)\n",
    "        \n",
    "        n_cv (int): number of folds in cross-validation\n",
    "        \n",
    "        verbose (int): Controls the verbosity, the higher, the more messages.\n",
    "        \n",
    "        jobs (int): number of cpus to specify for the parallelization \n",
    "        \n",
    "        Output:\n",
    "        ---------------------------\n",
    "        grid_search.best_estimator_ (sklearn model): the best fitted model employing grid search\n",
    "        \n",
    "        grid_search.best_params_ (dictionary): list of the parameters for the best fitted model employing grid search\n",
    "        \n",
    "        grid_search (list of sklearn models): list of all tried methods employing random search\n",
    "        \n",
    "    '''    \n",
    "    \n",
    "    print('Runnig Grid Search for Hyper-parameter Tuning  when Scoring is R-squared for ' + method + ' ..... ')\n",
    "    \n",
    "    if not grid:\n",
    "        grid = Create_grid_serach(method)\n",
    "    \n",
    "    grid_search = GridSearchCV(estimator = model, param_grid = grid, cv = n_cv, scoring= 'r2', n_jobs = jobs,\n",
    "                               verbose = verbose)\n",
    "    grid_search.fit(X, y)\n",
    "    \n",
    "    return grid_search.best_estimator_, grid_search.best_params_, grid_search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Build_fit_model(method, X_train, y_train):\n",
    "    \n",
    "    ''' This function builds and fits a model using the data provided.\n",
    "        \n",
    "        Input:\n",
    "        --------------------------\n",
    "        method (str): name of the method\n",
    "        \n",
    "        X_train (pandas dataframe): data for the predictors\n",
    "        \n",
    "        y_train (pandas dataframe, pandas serie): output data\n",
    "        \n",
    "        \n",
    "        Output:\n",
    "        ---------------------------\n",
    "        model (e.g. sklearn model): it is a trained model w.r.t. the method you specify\n",
    "        \n",
    "    '''\n",
    "        \n",
    "    if method == 'LR':\n",
    "        model = linear_model.LinearRegression()\n",
    "    elif method == 'LR_Ridge':\n",
    "        model = linear_model.RidgeCV()\n",
    "    elif method == 'LR_Lasso':\n",
    "        model = linear_model.LassoCV()\n",
    "    elif method == 'LR_Elastic':\n",
    "        model = linear_model.ElasticNetCV()\n",
    "    elif method == 'GAM':\n",
    "        model = GAM().fit(X_train, y_train)\n",
    "    elif method == 'RF':\n",
    "        model = RandomForestRegressor()\n",
    "    elif method == 'AdaB':\n",
    "        model = AdaBoostRegressor()\n",
    "    elif method == 'XGBoost':\n",
    "        model = xgboost.XGBRegressor()\n",
    "    elif method == 'SVR':\n",
    "        model = SVR()\n",
    "    elif method == 'KNN':\n",
    "        model = KNeighborsRegressor()\n",
    "    elif method == 'MLP':\n",
    "        model = MLPRegressor()\n",
    "    \n",
    "    if method == 'GAM':\n",
    "        model.gridsearch(X_train, y_train)\n",
    "    elif method in  ['LR']:\n",
    "        model = model.fit(X_train, y_train)\n",
    "    elif method in ['LR_Ridge', 'LR_Lasso', 'LR_Elastic', 'KNN', 'SVR', 'RF', 'AdaB', 'XGBoost', 'MLP']:\n",
    "        model, parameters, all_models = RandomSearch_Param_Tuning(model, method, 100, X_train, y_train)\n",
    "        \n",
    "    print('Parameters for ' + method)\n",
    "    pprint(model.get_params())\n",
    "    \n",
    "    os.makedirs(\"trained_models\", exist_ok=True)\n",
    "    joblib.dump(model, 'trained_models/' + method + '_trained_model.sav')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, file_path, model_name = None):\n",
    "    \n",
    "    ''' This function saves a built and fitted model as .sav using joblib.\n",
    "        \n",
    "        Input:\n",
    "        --------------------------\n",
    "        model (e.g. SKlearn models): it is a trained model\n",
    "        \n",
    "        file_path (str): where to save the model\n",
    "        \n",
    "        model_name (str): name of the model (optional)\n",
    "        \n",
    "        \n",
    "        Output:\n",
    "        ---------------------------\n",
    "        None\n",
    "    '''\n",
    "    \n",
    "    joblib.dump(model, file_path + model_name + '_trained_model.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(file_path):\n",
    "    \n",
    "    ''' This function loads a saved built and fitted model as .sav using joblib.\n",
    "        \n",
    "        Input:\n",
    "        --------------------------\n",
    "       \n",
    "        file_path (str): where to save the model\n",
    "        \n",
    "        \n",
    "        Output:\n",
    "        ---------------------------\n",
    "        loaded_model (e.g. SKlearn models): a built and fitted model\n",
    "\n",
    "    '''\n",
    "        \n",
    "    loaded_model = joblib.load(file_path)\n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prediction(method, X_train, X_val, y_train, y_val, X_test, y_test, output_variable, output_path, data_training,\n",
    "               data_test, grid_5km_shp, model = None):\n",
    "        \n",
    "    ''' This function makes prediction for the provided data and reports three metrics, i.e. MAE, MSE, R-squared.\n",
    "        \n",
    "        Input:\n",
    "        --------------------------\n",
    "        \n",
    "        method (str): name of the method\n",
    "        \n",
    "        X_train (pandas dataframe): data for the training\n",
    "        \n",
    "        X_val (pandas dataframe): data for the validation\n",
    "        \n",
    "        y_train (pandas dataframe, pandas serie): output data for the training\n",
    "        \n",
    "        y_val (pandas dataframe, pandas serie): output data for the validation\n",
    "        \n",
    "        X_test (pandas dataframe): data for the test\n",
    "        \n",
    "        y_test (pandas dataframe, pandas serie): output data for the test\n",
    "        \n",
    "        output_variable (str): name of the output variable\n",
    "        \n",
    "        model (e.g. SKlearn models): it is a trained model\n",
    "        \n",
    "        output_path (str): where to save the results\n",
    "        \n",
    "        data_training (pandas dataframe): entire training data\n",
    "        \n",
    "        data_test (pandas dataframe): entire test data\n",
    "        \n",
    "        grid_5km_shp (shape file): 5km grid saved as shape file provided to be able to save the results as shape files for the\n",
    "        further illustrations as maps\n",
    "        \n",
    "        model (e.g. SKlearn models): it is a trained model (optional)\n",
    "        \n",
    "        \n",
    "        Output:\n",
    "        ---------------------------\n",
    "        result (dictionary): a dictionary containing the performance of training, validation and test phase for \n",
    "        specified method. It contains MAE, MSE, R-squared\n",
    "        \n",
    "        y_pred (pandas dataframe): a dataframe containing the predictions\n",
    "        \n",
    "        model (e.g. SKlearn models): it is a trained model\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    print(method + ' is running ... ')\n",
    "    \n",
    "    if not model:\n",
    "        # If no trained model is provided, first, build and train the desired model\n",
    "        model = Build_fit_model(method, X_train, y_train)\n",
    "    \n",
    "    # Validation and Evaluation of the model\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_val)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = pd.DataFrame(y_pred, columns = [output_variable])\n",
    "\n",
    "    result = {'Method': method, 'MSE_train': mean_squared_error(y_train, y_pred_train),\n",
    "                            'MAE_train': mean_absolute_error(y_train, y_pred_train),\n",
    "                            'R_2_train': r2_score(y_train, y_pred_train),\n",
    "                            'MSE_val': mean_squared_error(y_val, y_pred_test),\n",
    "                            'MAE_val': mean_absolute_error(y_val, y_pred_test),\n",
    "                            'R_2_val': r2_score(y_val, y_pred_test), 'MSE_pred': mean_squared_error(y_test, y_pred),\n",
    "                            'MAE_pred': mean_absolute_error(y_test, y_pred),\n",
    "                            'R_2_pred': r2_score(y_test, y_pred)}\n",
    "    print(method + ' results:')\n",
    "    pprint(result)\n",
    "    \n",
    "#     Merge dataframes to make the final output dataset \n",
    "    data_result= pd.DataFrame()\n",
    "    data_result = data_result.append(data_training)\n",
    "    data_result = data_result.append(pd.concat([data_test.drop([output_variable], axis = 1),pd.DataFrame(y_pred)],axis=1))\n",
    "    data_result = data_result[['id', output_variable]]\n",
    "    data_result.to_csv((output_path + method + '/prediction_result_' + method + '.csv'), sep=',', index=False)\n",
    "    \n",
    "#     Merge dataframes to make the Ground Truth\n",
    "    GT = pd.DataFrame()\n",
    "    GT = GT.append(data_training)\n",
    "    GT = GT.append(pd.concat([data_test.drop([output_variable], axis = 1),pd.DataFrame(y_test)],axis=1))\n",
    "    GT = GT[['id', output_variable]]\n",
    "    GT.to_csv((output_path + 'GT/GT.csv'), sep=',', index=False)   \n",
    "    \n",
    "#     Make the difference output\n",
    "    data_diff_result= pd.DataFrame()\n",
    "    data_diff_result = data_diff_result.append(data_training)\n",
    "    data_diff_result[output_variable] = 0\n",
    "    pred_variable = 'pred'+output_variable\n",
    "    data_test = pd.concat([data_test, y_pred.rename(columns={output_variable: pred_variable})], axis=1)\n",
    "    data_test[output_variable] = data_test[output_variable] - data_test[pred_variable]\n",
    "    data_diff_result = data_diff_result.append(data_test.drop([pred_variable], axis = 1))\n",
    "    data_diff_result = data_diff_result[['id', output_variable]]\n",
    "    data_diff_result.to_csv((output_path + 'diff_' + method + '/prediction_result_diff_' + method + '.csv'), sep=',', index=False)\n",
    "    \n",
    "#     Make shp files\n",
    "    merged_data = grid_5km_shp.merge(data_result, left_on=\"id\", right_on=\"id\")\n",
    "#     merged_data_GT = grid_5km_shp.merge(GT, left_on=\"id\", right_on=\"id\")\n",
    "    merged_data_diff = grid_5km_shp.merge(data_diff_result, left_on=\"id\", right_on=\"id\")\n",
    "#     save the GeoDataFrame\n",
    "    merged_data.to_file(driver = 'ESRI Shapefile', filename= output_path + method + '/' + method + '_shape.shp')\n",
    "#     merged_data.to_file(driver = 'ESRI Shapefile', filename= output_path + 'GT/GT_shape.shp')\n",
    "    merged_data_diff.to_file(driver = 'ESRI Shapefile', filename= output_path + 'diff_'+ method + '/diff_' + method + '_shape.shp')\n",
    "    \n",
    "    return result, y_pred, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prediction_without_validation(method, X_train, y_train, X_test, y_test, output_variable, output_path, data_training,\n",
    "               data_test, grid_5km_shp, model = None):\n",
    "        \n",
    "    ''' This function makes prediction for the provided data and reports three metrics, i.e. MAE, MSE, R-squared.\n",
    "        \n",
    "        Input:\n",
    "        --------------------------\n",
    "        \n",
    "        method (str): name of the method\n",
    "        \n",
    "        X_train (pandas dataframe): data for the training\n",
    "        \n",
    "        X_val (pandas dataframe): data for the validation\n",
    "        \n",
    "        y_train (pandas dataframe, pandas serie): output data for the training\n",
    "        \n",
    "        y_val (pandas dataframe, pandas serie): output data for the validation\n",
    "        \n",
    "        X_test (pandas dataframe): data for the test\n",
    "        \n",
    "        y_test (pandas dataframe, pandas serie): output data for the test\n",
    "        \n",
    "        output_variable (str): name of the output variable\n",
    "        \n",
    "        model (e.g. SKlearn models): it is a trained model\n",
    "        \n",
    "        output_path (str): where to save the results\n",
    "        \n",
    "        data_training (pandas dataframe): entire training data\n",
    "        \n",
    "        data_test (pandas dataframe): entire test data\n",
    "        \n",
    "        grid_5km_shp (shape file): 5km grid saved as shape file provided to be able to save the results as shape files for the\n",
    "        further illustrations as maps\n",
    "        \n",
    "        model (e.g. SKlearn models): it is a trained model (optional)\n",
    "        \n",
    "        \n",
    "        Output:\n",
    "        ---------------------------\n",
    "        result (dictionary): a dictionary containing the performance of training, validation and test phase for \n",
    "        specified method. It contains MAE, MSE, R-squared\n",
    "        \n",
    "        y_pred (pandas dataframe): a dataframe containing the predictions\n",
    "        \n",
    "        model (e.g. SKlearn models): it is a trained model\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    print(method + ' is running ... ')\n",
    "    \n",
    "    if not model:\n",
    "        # If no trained model is provided, first, build and train the desired model\n",
    "        model = Build_fit_model(method, X_train, y_train)\n",
    "    \n",
    "    # Evaluation of the model\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = pd.DataFrame(y_pred, columns = [output_variable])\n",
    "\n",
    "    result = {'Method': method, 'MSE_train': mean_squared_error(y_train, y_pred_train),\n",
    "                            'MAE_train': mean_absolute_error(y_train, y_pred_train),\n",
    "                            'R_2_train': r2_score(y_train, y_pred_train),\n",
    "                            'MSE_pred': mean_squared_error(y_test, y_pred),\n",
    "                            'MAE_pred': mean_absolute_error(y_test, y_pred),\n",
    "                            'R_2_pred': r2_score(y_test, y_pred)}\n",
    "    print(method + ' results:')\n",
    "    pprint(result)\n",
    "    \n",
    "#     Merge dataframes to make the final output dataset \n",
    "    data_result= pd.DataFrame()\n",
    "    data_result = data_result.append(data_training)\n",
    "    data_result = data_result.append(pd.concat([data_test.drop([output_variable], axis = 1),pd.DataFrame(y_pred)],axis=1))\n",
    "    data_result = data_result[['id', output_variable]]\n",
    "    data_result.to_csv((output_path + method + '/prediction_result_' + method + '.csv'), sep=',', index=False)\n",
    "    \n",
    "#     Merge dataframes to make the Ground Truth\n",
    "    GT = pd.DataFrame()\n",
    "    GT = GT.append(data_training)\n",
    "    GT = GT.append(pd.concat([data_test.drop([output_variable], axis = 1),pd.DataFrame(y_test)],axis=1))\n",
    "    GT = GT[['id', output_variable]]\n",
    "    GT.to_csv((output_path + 'GT/GT.csv'), sep=',', index=False)   \n",
    "    \n",
    "#     Make the difference output\n",
    "    data_diff_result= pd.DataFrame()\n",
    "    data_diff_result = data_diff_result.append(data_training)\n",
    "    data_diff_result[output_variable] = 0\n",
    "    pred_variable = 'pred'+output_variable\n",
    "    data_test = pd.concat([data_test, y_pred.rename(columns={output_variable: pred_variable})], axis=1)\n",
    "    data_test[output_variable] = data_test[output_variable] - data_test[pred_variable]\n",
    "    data_diff_result = data_diff_result.append(data_test.drop([pred_variable], axis = 1))\n",
    "    data_diff_result = data_diff_result[['id', output_variable]]\n",
    "    data_diff_result.to_csv((output_path + 'diff_' + method + '/prediction_result_diff_' + method + '.csv'), sep=',', index=False)\n",
    "    \n",
    "#     Make shp files\n",
    "    merged_data = grid_5km_shp.merge(data_result, left_on=\"id\", right_on=\"id\")\n",
    "#     merged_data_GT = grid_5km_shp.merge(GT, left_on=\"id\", right_on=\"id\")\n",
    "    merged_data_diff = grid_5km_shp.merge(data_diff_result, left_on=\"id\", right_on=\"id\")\n",
    "#     save the GeoDataFrame\n",
    "    merged_data.to_file(driver = 'ESRI Shapefile', filename= output_path + method + '/' + method + '_shape.shp')\n",
    "#     merged_data.to_file(driver = 'ESRI Shapefile', filename= output_path + 'GT/GT_shape.shp')\n",
    "    merged_data_diff.to_file(driver = 'ESRI Shapefile', filename= output_path + 'diff_'+ method + '/diff_' + method + '_shape.shp')\n",
    "    \n",
    "    return result, y_pred, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Build_fit_all_methods(methods, X_train, y_train):\n",
    "    \n",
    "    ''' This function builds and fits bunch of models the provided data.\n",
    "        \n",
    "        Input:\n",
    "        --------------------------\n",
    "        methods (str): name of the method\n",
    "        \n",
    "        X_train (pandas dataframe): data for the predictors\n",
    "        \n",
    "        y_train (pandas dataframe, pandas serie): output data\n",
    "        \n",
    "        \n",
    "        Output:\n",
    "        ---------------------------\n",
    "        models (list of e.g. sklearn model): list of trained model w.r.t. the specified methods\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    models = []\n",
    "    for method in methods:\n",
    "        # Build and fit the model with the proper data\n",
    "        models.append(Build_fit_model(method, X_train, y_train))\n",
    "    \n",
    "    return models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
